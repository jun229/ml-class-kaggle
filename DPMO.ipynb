{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c00cf8-d7a8-487f-abe3-cb4b9d64aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.modules[\"numpy._core\"] = importlib.import_module(\"numpy.core\")\n",
    "sys.modules[\"numpy._core.multiarray\"] = importlib.import_module(\"numpy.core.multiarray\")\n",
    "sys.modules[\"numpy._core.umath\"] = importlib.import_module(\"numpy.core.umath\")\n",
    "\n",
    "data = pd.read_pickle(r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\data\\train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa46fa2-1db5-4fab-8514-258a10b0ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: (40000, 2, 24, 24) (20000, 2, 24, 24) feat: (40000, 2560) (20000, 2560)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 – Imports & data loading\n",
    "import numpy as np, pandas as pd, pickle, os\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# load raw train/test\n",
    "base = r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\data\"\n",
    "train = pickle.load(open(f\"{base}/train.pkl\",\"rb\"))\n",
    "test  = pickle.load(open(f\"{base}/test.pkl\",\"rb\"))\n",
    "\n",
    "X_raw      = np.stack([np.stack(train[\"img1\"].values),\n",
    "                       np.stack(train[\"img2\"].values)], axis=1)\n",
    "y          = train[\"label\"].values\n",
    "X_test_raw = np.stack([np.stack(test[\"img1\"].values),\n",
    "                       np.stack(test[\"img2\"].values)], axis=1)\n",
    "test_ids   = test[\"id\"]\n",
    "\n",
    "# load pre‑extracted CNN features\n",
    "d_train = np.load(r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\notebooks\\data\\processed\\rps_mobilenet_feats.npz\")\n",
    "X_feat, y_feat = d_train[\"X_feat\"], d_train[\"y_feat\"]\n",
    "X_test_feat   = np.load(r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\notebooks\\data\\processed\\X_test_feat.npy\")\n",
    "print(\"raw:\", X_raw.shape, X_test_raw.shape, \"feat:\", X_feat.shape, X_test_feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593747c6-8b55-40f0-bc9f-ba5db5773358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 – Define the extractor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class RPSFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return X.reshape(X.shape[0], -1).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "055b7d87-653a-4ad8-8522-8776bfdefce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITTERATION 2: NEW CELL\n",
    "# IM TRYING TO OPTIMIZE THE CNN\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Transform for MobileNetV2 input (96x96, 3-channels, normalized)\n",
    "tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define custom dataset for image pairs\n",
    "class RPSPair(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y=None, transform=None):\n",
    "        self.X = X.astype(np.uint8)\n",
    "        self.y = y\n",
    "        self.tf = transform\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        a, b = self.X[idx]\n",
    "        ta = self.tf(a)\n",
    "        tb = self.tf(b)\n",
    "        pair = torch.cat([ta, tb], dim=0)  # shape: (6, 96, 96)\n",
    "        if self.y is not None:\n",
    "            return pair, (1 if self.y[idx] > 0 else 0)\n",
    "        return pair\n",
    "\n",
    "# Train/val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_raw, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_ds = RPSPair(X_tr, y_tr, transform=tf)\n",
    "val_ds   = RPSPair(X_val, y_val, transform=tf)\n",
    "train_ld = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_ld   = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b78b564-7ad7-44de-9d99-4d08d404f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2 loaded + partially unfrozen for fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# ITTERATION 2: NEW CELL\n",
    "# IM TRYING TO OPTIMIZE THE CNN\n",
    "\n",
    "# Optimized fine-tuning setup for MobileNetV2 (CPU-safe)\n",
    "import torch, torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained MobileNetV2 backbone (without classifier head)\n",
    "mobilenet = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Freeze all layers first\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze only the last conv block\n",
    "for param in mobilenet.features[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Replace classifier with a binary output head\n",
    "mobilenet.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(mobilenet.last_channel, 1)  # Binary classification output\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "mobilenet = mobilenet.to(device)\n",
    "\n",
    "print(\"MobileNetV2 loaded + partially unfrozen for fine-tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3227f02a-e3c7-4284-a71d-120173cb7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss = 0.6456\n",
      " → val acc = 0.6637\n",
      "Epoch 2 loss = 0.6110\n",
      " → val acc = 0.7050\n",
      "Epoch 3 loss = 0.5923\n",
      " → val acc = 0.7079\n"
     ]
    }
   ],
   "source": [
    "# ITTERATION 2: NEW CELL\n",
    "# IM TRYING TO OPTIMIZE THE CNN\n",
    "\n",
    "# Fine‑tune MobileNetV2 on image pairs (fixed avgpool)\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1) Ensure single‑threaded CPU usage\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# 2) Define the pair‐wise model\n",
    "class PairMobileNet(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone.features\n",
    "        # explicit global avg pool\n",
    "        self.avgpool  = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # head: concatenated embeddings → binary logit\n",
    "        emb_size = backbone.last_channel * 2\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(emb_size, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # split two 3‑channel images\n",
    "        a, b = x[:, :3], x[:, 3:]\n",
    "        # extract and pool\n",
    "        fa = self.avgpool(self.backbone(a))  # (B,1280,1,1)\n",
    "        fb = self.avgpool(self.backbone(b))\n",
    "        # flatten\n",
    "        fa = fa.view(fa.size(0), -1)         # (B,1280)\n",
    "        fb = fb.view(fb.size(0), -1)\n",
    "        # concat & head\n",
    "        z  = torch.cat([fa, fb], dim=1)      # (B,2560)\n",
    "        return self.head(z).squeeze(1)       # (B,)\n",
    "\n",
    "# 3) Instantiate and freeze cores\n",
    "model = PairMobileNet(mobilenet).to(device)\n",
    "for param in model.backbone[:-2].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 4) Optimizer & loss\n",
    "opt     = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4, weight_decay=1e-5\n",
    ")\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 5) Tiny DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "# 6) Training loop (2–3 epochs to start)\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), (yb>0).float().to(device)\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss   = loss_fn(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    print(f\"Epoch {epoch+1} loss = {total_loss/len(train_ds):.4f}\")\n",
    "\n",
    "    # quick validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = (model(xb)>0).cpu()\n",
    "            correct += (preds == (yb>0)).sum().item()\n",
    "    print(f\" → val acc = {correct/len(val_ds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6c9489-584c-4337-bb9e-65e6e6bc636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP trained\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 – Train the MLP head\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,256),\n",
    "                    max_iter=200, random_state=42)\n",
    "mlp.fit(X_feat, (y_feat>0).astype(int))\n",
    "print(\"MLP trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e03ead-8127-4fd9-a577-597d80defab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast RBF approx pipeline trained.\n"
     ]
    }
   ],
   "source": [
    "# CELL 4 – Fast “RBF‑SVM” via random Fourier + SGD\n",
    "from joblib import Memory\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "mem = Memory(\".cache\", verbose=0)\n",
    "\n",
    "fast_svm = Pipeline([\n",
    "    (\"feat\",   RPSFeatureExtractor()),\n",
    "    (\"pca\",    PCA(n_components=80, random_state=42)),\n",
    "    (\"rbf\",    RBFSampler(gamma=0.01, n_components=500, random_state=42)),\n",
    "    (\"cls\",    SGDClassifier(\n",
    "                  loss=\"hinge\",\n",
    "                  max_iter=1000,\n",
    "                  tol=1e-3,\n",
    "                  random_state=42,\n",
    "                  n_jobs=2\n",
    "              ))\n",
    "], memory=mem)\n",
    "\n",
    "fast_svm.fit(X_raw, y)\n",
    "print(\"Fast RBF approx pipeline trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7465b34-587d-41af-96b2-7aa0db7c5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 15.58, NNZs: 500, Bias: 0.326842, T: 32000, Avg. loss: 1.392417\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.81, NNZs: 500, Bias: 0.789278, T: 64000, Avg. loss: 1.044666\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.61, NNZs: 500, Bias: 0.435006, T: 96000, Avg. loss: 1.013664\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.56, NNZs: 500, Bias: 0.570230, T: 128000, Avg. loss: 0.997572\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.64, NNZs: 500, Bias: -0.653960, T: 160000, Avg. loss: 0.982639\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.77, NNZs: 500, Bias: 0.030540, T: 192000, Avg. loss: 0.974293\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 11.21, NNZs: 500, Bias: -0.768771, T: 224000, Avg. loss: 0.973472\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 11.59, NNZs: 500, Bias: -0.279575, T: 256000, Avg. loss: 0.969375\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.46, NNZs: 500, Bias: 0.031834, T: 288000, Avg. loss: 0.962793\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.55, NNZs: 500, Bias: 0.219078, T: 320000, Avg. loss: 0.959839\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.65, NNZs: 500, Bias: 0.485268, T: 352000, Avg. loss: 0.960365\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 11.82, NNZs: 500, Bias: 0.085309, T: 384000, Avg. loss: 0.959159\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.70, NNZs: 500, Bias: 0.153437, T: 416000, Avg. loss: 0.956081\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.76, NNZs: 500, Bias: -0.099492, T: 448000, Avg. loss: 0.955601\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.80, NNZs: 500, Bias: 0.138326, T: 480000, Avg. loss: 0.953803\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.86, NNZs: 500, Bias: 0.132106, T: 512000, Avg. loss: 0.953421\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 12.00, NNZs: 500, Bias: 0.291807, T: 544000, Avg. loss: 0.953095\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 12.02, NNZs: 500, Bias: -0.137841, T: 576000, Avg. loss: 0.951534\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 11.99, NNZs: 500, Bias: 0.363952, T: 608000, Avg. loss: 0.950134\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 11.99, NNZs: 500, Bias: 0.004892, T: 640000, Avg. loss: 0.950059\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 12.05, NNZs: 500, Bias: -0.097366, T: 672000, Avg. loss: 0.950246\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 12.07, NNZs: 500, Bias: 0.589487, T: 704000, Avg. loss: 0.948744\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 12.06, NNZs: 500, Bias: 0.362403, T: 736000, Avg. loss: 0.948164\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12.10, NNZs: 500, Bias: 0.101936, T: 768000, Avg. loss: 0.948407\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12.12, NNZs: 500, Bias: -0.025248, T: 800000, Avg. loss: 0.948813\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12.21, NNZs: 500, Bias: -0.046550, T: 832000, Avg. loss: 0.948398\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12.24, NNZs: 500, Bias: 0.384369, T: 864000, Avg. loss: 0.947680\n",
      "Total training time: 1.05 seconds.\n",
      "Convergence after 27 epochs took 1.05 seconds\n",
      "Hold‑out ensemble acc: 0.6854\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – Quick hold‑out test (optional)\n",
    "# Single call, all together\n",
    "Xr_tr, Xr_va, Xc_tr, Xc_va, y_tr_raw, y_va_raw, y_tr_bin, y_va_bin = train_test_split(\n",
    "    X_raw, X_feat, y, (y_feat>0).astype(int),\n",
    "    test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "fast_svm.fit(Xr_tr, y_tr_raw)\n",
    "mlp.fit(Xc_tr, y_tr_bin)\n",
    "\n",
    "y_s = fast_svm.predict(Xr_va)\n",
    "y_m = np.where(mlp.predict(Xc_va)>0, 1, -1)\n",
    "\n",
    "ens = np.where(y_s + y_m > 0, 1, -1)\n",
    "acc = (ens == y_va_raw).mean()\n",
    "print(f\"Hold‑out ensemble acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba42bc6-a8c3-4625-8937-81c634cc7e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5165\n",
      "0.73425\n"
     ]
    }
   ],
   "source": [
    "print(fast_svm.score(Xr_va, y_va_raw))\n",
    "print(mlp.score(Xc_va, y_va_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4d876c-6f89-4fab-b14d-d131b48c19f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg hold‑out acc: 0.7141\n",
      "MLP   hold‑out acc: 0.7342\n",
      "Ensembled hold‑out acc: 0.7342\n"
     ]
    }
   ],
   "source": [
    "# CELL 5d – Compare LR, MLP, and their ensemble on CNN features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1) Train/test split on X_feat\n",
    "X_tr, X_va, y_tr_bin, y_va_bin = train_test_split(\n",
    "    X_feat, (y_feat>0).astype(int),\n",
    "    test_size=0.2, stratify=y_feat, random_state=42\n",
    ")\n",
    "\n",
    "# 2) Fit Logistic Regression head\n",
    "lr = LogisticRegression(max_iter=500, random_state=42)\n",
    "lr.fit(X_tr, y_tr_bin)\n",
    "y_lr = lr.predict(X_va)\n",
    "\n",
    "# 3) Fit MLP head\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512,256),\n",
    "                    max_iter=200, random_state=42)\n",
    "mlp.fit(X_tr, y_tr_bin)\n",
    "y_mlp = mlp.predict(X_va)\n",
    "\n",
    "# 4) Ensemble by hard vote\n",
    "#   map {0,1} to {-1,+1} for voting, then map back\n",
    "v_lr  = np.where(y_lr > 0, 1, -1)\n",
    "v_mlp = np.where(y_mlp > 0, 1, -1)\n",
    "ensemble = np.sign(v_lr + v_mlp)           # ties → 0\n",
    "# break ties by defaulting to MLP’s vote:\n",
    "tie_idx = (ensemble == 0)\n",
    "ensemble[tie_idx] = v_mlp[tie_idx]\n",
    "y_ens = np.where(ensemble > 0, 1, 0)        # back to {0,1}\n",
    "\n",
    "# 5) Report accuracies\n",
    "acc_lr  = accuracy_score(y_va_bin, y_lr)\n",
    "acc_mlp = accuracy_score(y_va_bin, y_mlp)\n",
    "acc_ens = accuracy_score(y_va_bin, y_ens)\n",
    "print(f\"LogReg hold‑out acc: {acc_lr:.4f}\")\n",
    "print(f\"MLP   hold‑out acc: {acc_mlp:.4f}\")\n",
    "print(f\"Ensembled hold‑out acc: {acc_ens:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455791c3-198b-4006-9275-2770a34e370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved MLP‑only submission → C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\submissions\\cnn_mlp_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6a\n",
    "\n",
    "# CELL 6c – Train MLP on full CNN features & save submission.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle, os\n",
    "\n",
    "# 1) Reload train/test feature arrays if needed\n",
    "#    (skip if X_feat, y_feat, X_test_feat, test_ids already in memory)\n",
    "train_npz    = np.load(\"data/processed/rps_mobilenet_feats.npz\")\n",
    "X_feat, y_feat = train_npz[\"X_feat\"], train_npz[\"y_feat\"]\n",
    "X_test_feat  = np.load(\"data/processed/x_test_feat.npy\")\n",
    "\n",
    "test = pickle.load(open(\n",
    "    r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\data\\test.pkl\",\n",
    "    \"rb\"\n",
    "))\n",
    "test_ids = test[\"id\"].values\n",
    "\n",
    "# 2) Train MLP on all training features\n",
    "mlp_final = MLPClassifier(hidden_layer_sizes=(512,256),\n",
    "                          max_iter=200,\n",
    "                          random_state=42,\n",
    "                          verbose=False)\n",
    "mlp_final.fit(X_feat, (y_feat>0).astype(int))\n",
    "\n",
    "# 3) Predict on test features\n",
    "y_test = mlp_final.predict(X_test_feat)      # {0,1}\n",
    "y_test = np.where(y_test>0, 1, -1)           # map to {−1,+1}\n",
    "\n",
    "# 4) Save submission.csv\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "out_path = out_path = r\"C:\\Users\\brian\\INFO 2950 - Intro to Data Science\\Other Projects\\rock-paper-scissors-pt2\\submissions\\cnn_mlp_submission.csv\"\n",
    "pd.DataFrame({\"id\": test_ids, \"label\": y_test}) \\\n",
    "  .to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved MLP‑only submission → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc53ca10-80e6-4b94-a5ed-0e8e1e804089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 – Ensemble on the real test set & save CSV\n",
    "y_mlp = np.where(mlp.predict(X_test_feat)>0, 1, -1)\n",
    "y_svm = best_svm.predict(X_test_raw)\n",
    "sum_ = y_mlp + y_svm\n",
    "y_ens = np.where(sum_>0,1,-1)\n",
    "ties = (sum_==0); y_ens[ties] = y_svm[ties]\n",
    "\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "pd.DataFrame({\"id\": test_ids, \"label\": y_ens}) \\\n",
    "  .to_csv(\"submissions/ensemble_mlp_svm.csv\", index=False)\n",
    "print(\"Saved ensemble CSV with test‑set predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de12e0-2fb4-43ea-8e79-c99c5c7ece75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a82b4f-994c-49af-b512-70c8e1514df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
